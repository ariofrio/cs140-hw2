12 templated_functions_MULTI_TIME
# Name Calls Subrs Excl Incl ProfileCalls # <metadata><attribute><name>Metric Name</name><value>TIME</value></attribute><attribute><name>Starting Timestamp</name><value>1358972133948724</value></attribute><attribute><name>UTC Time</name><value>2013-01-23T20:17:46Z</value></attribute><attribute><name>Local Time</name><value>2013-01-23T12:17:46-08:00</value></attribute><attribute><name>Timestamp</name><value>1358972266705073</value></attribute><attribute><name>Hostname</name><value>pdafm-6-5.local</value></attribute><attribute><name>OS Name</name><value>Linux</value></attribute><attribute><name>OS Version</name><value>#1 SMP Tue May 31 13:22:04 EDT 2011</value></attribute><attribute><name>OS Release</name><value>2.6.18-238.12.1.el5</value></attribute><attribute><name>OS Machine</name><value>x86_64</value></attribute><attribute><name>Node Name</name><value>pdafm-6-5.local</value></attribute><attribute><name>TAU Architecture</name><value>x86_64</value></attribute><attribute><name>TAU Config</name><value> -cc=pgcc -c++=pgCC -fortran=pgi -prefix=/home/beta/tau/2.19-pgi -pdt=/home/beta/pdt/3.15-pgi -mpi -mpiinc=/opt/openmpi/pgi/mx/include -mpilib=/opt/openmpi/pgi/mx/lib</value></attribute><attribute><name>TAU Makefile</name><value>/home/beta/tau/2.19-pgi/x86_64/lib/Makefile.tau-mpi-pdt-pgi</value></attribute><attribute><name>TAU Version</name><value>tau-2.19</value></attribute><attribute><name>pid</name><value>19508</value></attribute><attribute><name>CPU Vendor</name><value>AuthenticAMD</value></attribute><attribute><name>CPU Vendor</name><value>AuthenticAMD</value></attribute><attribute><name>CPU Type</name><value>Quad-Core AMD Opteron(tm) Processor 8380</value></attribute><attribute><name>CPU MHz</name><value>2493.377</value></attribute><attribute><name>Cache Size</name><value>512 KB</value></attribute><attribute><name>CPU Cores</name><value>4</value></attribute><attribute><name>Memory Size</name><value>528724472 kB</value></attribute><attribute><name>Executable</name><value>/home/cs140-ucsb-38/hw2/parallel/assn2</value></attribute><attribute><name>CWD</name><value>/home/cs140-ucsb-38/hw2/parallel</value></attribute><attribute><name>username</name><value>cs140-ucsb-38</value></attribute><attribute><name>MPI Processor Name</name><value>pdafm-6-5.local</value></attribute><attribute><name>TAU_CALLPATH</name><value>off</value></attribute><attribute><name>TAU_CALLPATH_DEPTH</name><value>2</value></attribute><attribute><name>TAU_COMM_MATRIX</name><value>off</value></attribute><attribute><name>TAU_COMPENSATE</name><value>off</value></attribute><attribute><name>TAU_PROFILE</name><value>on</value></attribute><attribute><name>TAU_PROFILE_FORMAT</name><value>profile</value></attribute><attribute><name>TAU_THROTTLE</name><value>on</value></attribute><attribute><name>TAU_THROTTLE_NUMCALLS</name><value>100000</value></attribute><attribute><name>TAU_THROTTLE_PERCALL</name><value>10</value></attribute><attribute><name>TAU_TRACE</name><value>off</value></attribute><attribute><name>TAU_TRACK_HEADROOM</name><value>off</value></attribute><attribute><name>TAU_TRACK_HEAP</name><value>off</value></attribute><attribute><name>TAU_TRACK_MESSAGE</name><value>off</value></attribute></metadata>
"int main(int, char **) C [{powermethod.c} {14,1}-{78,1}]  " 1 7 236 132755310 0 GROUP="TAU_DEFAULT" 
"MPI_Init()  " 1 0 1162378 1162378 0 GROUP="MPI" 
"MPI_Comm_rank()  " 1004 0 387 387 0 GROUP="MPI" 
"MPI_Comm_size()  " 1002 0 1113 1113 0 GROUP="MPI" 
"void generatematrix(double *, int) C [{functions.c} {41,1}-{63,1}]  " 1 3 146472 180561 0 GROUP="TAU_USER" 
"void debug_matrix(double *, int, int) C [{functions.c} {19,1}-{30,1}]  " 1 0 34089 34089 0 GROUP="TAU_USER" 
"void generatevec(double *, int) C [{functions.c} {66,1}-{78,1}]  " 1 1 2 3 0 GROUP="TAU_USER" 
"double powerMethod(double *, double *, int, int) C [{functions.c} {128,1}-{152,1}]  " 1 1001 1137 131405670 0 GROUP="TAU_USER" 
"void matVec(double *, double *, int) C [{functions.c} {91,1}-{117,1}]  " 1000 4000 123933420 131404533 0 GROUP="TAU_USER" 
"MPI_Bcast()  " 1000 0 458587 458587 0 GROUP="MPI" 
"MPI_Gather()  " 1000 0 7011028 7011028 0 GROUP="MPI" 
"MPI_Finalize()  " 1 0 6461 6461 0 GROUP="MPI" 
0 aggregates
1 userevents
# eventname numevents max min mean sumsqr
"Message size for broadcast" 1000 65536 65536 65536 4294967296000
